\section{Problema 8}
\subsection{Enunciat}
Consider the following randomized algorithm.
\begin{algorithm}
\caption{}
\begin{algorithmic}[1]
\Function{RWVC}{$G=\{V,E\}$} \Comment{$G$:weighted graph}
\State $U$ = $\emptyset$;
\While{$E \neq \emptyset$}
    \State{Select an edge $e = (v,t)$};
    \State{Randomly choose $x$ from $\{v, t\}$ with $P[x=v]=\frac{w(t)}{w(v)+w(t)}$};
    \State{$U = U \cup \{x\}$};
    \State{$E = E - \{e | x \text{ is an end-point of } e\}$}
\EndWhile
\State{\Return $U$}
\EndFunction
\end{algorithmic}
\end{algorithm}

Prove that \textbf{RWVC} is a randomized 2-approximation for \textbf{Minimum weighted vertex cover} problem.
\subsection{Solució}

Per veure que \textbf{RWVC} es una 2-aproximació de \textbf{Minimum weighted vertex cover} problem hem de demostrar el següent:
\[
w(s) \leq 2w(s^{*})
\]
On:
\begin{itemize}
    \item $s^{*}$ és la solució òptima
    \item $s$ és la solució obtinguda amb \textbf{RWVC}
    \item $s_i$ és la solució acumulada a la iteració $i$
    \item $w(X)$ és la suma total de pesos al conjunt $X$
\end{itemize}
\newpage
\subsubsection{Demostració}
Per començar definirem el següent lema:
\newline
\par
\textbf{Lema b}: L'esperança de la suma dels pesos que apareixen tant a $s$ com a $s^{*}$, és més gran que l'esperança de la suma dels pesos dels elements que apareixen a $s$ però no a $s^{*}$. Per tant:
\[
E[w(s \cap s^{*})] \geq E[w(s / s^{*})]
\]
\textbf{Demostració lema b:}
\newline
Ho demostrarem per inducció. Primer demostrarem el cas base: 
\[
E[w(s_0 \cap s^{*})] \geq E[w(s_0 / s^{*})]
\]

A cada iteració agafem una aresta $(u,v) \in E$ i triem un dels dos vèrtexs amb probabilitat  
\[
P[u]=\frac{w(u)}{w(u)+w(v)}
\]
pel vèrtex $u$ i probabilitat
\[
P[v]=1-P[u]
\]
%TODO: if this is minimization, s* should have the minimum weight vertexs instead?
pel vèrtex $v$. Per cada aresta, la solució $s^{*}$ agafa el vèrtex de més pes. Es a dir, sempre que agafem el vèrtex de més pes estem incrementant $w(s \cap s^{*})$, i en cas d'agafar el més petit incrementem $w(s/s^{*})$.
%TODO: should this be demonstrated developing the Expected value formula?
Com que és més probable agafar el node de més pes, i abans de la primera iteració $w(s_0 \cap s^{*}) = w(s_0 / s^{*})$, el més probable és que comencem augmentant $w(s \cap s^{*})$ i, per tant
\[
E[w(s_0 \cap s^{*})] \geq E[w(s_0 / s^{*})]
\]

A continuació demostrarem el cas general (suposem que és cert per a $i$ i demostrem que és cert per a $i+1$):
\[
\forall_i(E[w(s_i \cap s^{*})] \geq E[w(s_i / s^{*})] \Rightarrow E[w(s_{i+1} \cap s^{*})] \geq E[w(s_{i+1}/s^{*})])
\]

%TODO: is this enough to prove the induction step?
Amb el mateix raonament que al cas base, si en una iteració $i$ tenim 
\[
w(s_i \cap s^{*}) \geq w(s_i / s^{*})
\]
llavors
\[
E[w(s_{i+1} \cap s^{*})] \geq E[w(s_{i+1} / s^{*})]
\]
\renewcommand\qedsymbol{$\square$}
\qed
\newpage

%TODO: lemma a is supposed to be applied here. Some of this definitions should be Expected values
Ara tenim:
\begin{itemize}
    \item $w_c = w(s \cap s^{*})$
    \item $w_e = w(s / s^{*})$
    \item $w_{c'} = w(s \cap s^{*})$
    \item $w(s) = w_c+w_e$
    \item $w(s^{*}) = w_c+w_{c'}$
\end{itemize}
\begin{eqnarray}
    w_c+w_e \leq w_c+w_e \nonumber\\ 
    w_c+w_e \leq w_c+w_e+w_{c'}  \nonumber\\ 
    w(s) \leq w(s*)+w_e  \nonumber
\end{eqnarray}
Per canviar $w_e$ per $w(s^{*})$ i obtenir $w_e \leq w(s^{*})*2$, demostrem $w_e \leq w(s^{*})$.
Pel \textbf{lema b} tenim:
\begin{eqnarray}
    w_c \geq w_e \nonumber\\ 
    w_c+w_{c'} \geq w_e  \nonumber\\ 
    w(s^{*}) \geq w_e  \nonumber
\end{eqnarray}
\renewcommand\qedsymbol{$\blacksquare$}
\qed